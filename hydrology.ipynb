{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boiler Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2 as cv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "from noise import pnoise2, snoise2\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy import interpolate\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "startTime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Parameters Of The Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ps = 0.05 ## probability of symetric branch\n",
    "Pa = 0.3 ## probability of asymetric branch\n",
    "Pc = 1-(Ps+Pa) ## probability of continium ( growth)\n",
    "inputDomain='taiwan-outline-bigger.png'\n",
    "inputTerrain='taiwan-terrain-bigger.png'\n",
    "inputRiverSlope='taiwan-riverslope-bigger.png'\n",
    "globalseed=4314\n",
    "N_majorRivers=10\n",
    "zeta = 10 # elevation range to include in candidate node selection\n",
    "slopeRate = 30 # Maximum rate at which rivers climb\n",
    "edgeLength = 20\n",
    "eta = .75   #   eta * edgeLength is the minimum distance from a node to the coast\n",
    "sigma = .75 # sigma * edgeLength is the minimum distance between two nodes\n",
    "rwidth=6 # \n",
    "##initializations of nonparameter global variables\n",
    "\n",
    "nodecounter = 0;\n",
    "nodes=[]\n",
    "candidates=[]\n",
    "G = nx.DiGraph() # a bidirectional graph, represents the hydrological system?\n",
    "mouthnodes=[]    # the nodes of the major river mouths\n",
    "Gkd=None         # a ckDTree. represents nodes' positions? implements the paper's terrain model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Base Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgorg=cv.imread(inputDomain)\n",
    "img  = imgorg.copy()\n",
    "print('Terrain Outline')\n",
    "plt.imshow(img)\n",
    "random.seed(globalseed)\n",
    "\n",
    "terrainSlope = Image.open(inputTerrain)\n",
    "terrainSlope = terrainSlope.convert('L')\n",
    "plt.show()\n",
    "print('Terrain Slope Input')\n",
    "plt.imshow(terrainSlope)\n",
    "terrainSlope = terrainSlope.load()\n",
    "\n",
    "riverSlope = Image.open(inputRiverSlope)\n",
    "riverSlope = riverSlope.convert('L')\n",
    "plt.show()\n",
    "print('River Slope Input')\n",
    "plt.imshow(riverSlope)\n",
    "riverSlope = riverSlope.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find contour of the ROI, This will be Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # a black-and-white version of the input image\n",
    "ret, thresh = cv.threshold(imgray, 127, 255, 0)\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "cv.drawContours(img, contours, -1, (0,255,0), 2)\n",
    "test = cv.cvtColor(thresh, cv.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(contours) > 1:\n",
    "    print('WARNING: Multiple contours identified. The program may not have correctly')\n",
    "    print('identified the land.')\n",
    "\n",
    "contour = contours[0]\n",
    "contour=contour.reshape(-1,2)\n",
    "contour=np.flip(contour,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select first point at a ranndom offset, try to select the following points such as that the highest probability ( on a nomal distribution) is that they are furthest away from each other \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "points = []                            # the array of all the river start points\n",
    "random.seed(globalseed)\n",
    "idx = random.randint(0,len(contour)-1) # the first river\n",
    "points.append(contour[idx])\n",
    "N=N_majorRivers\n",
    "dist = len(contours[0])/N\n",
    "for i in range(1,N):\n",
    "    newIdx = int((idx+i*dist+random.gauss(0, dist/6))%len(contours[0]))\n",
    "    points.append(contour[newIdx])\n",
    "    img2 = img.copy()\n",
    "print(points)\n",
    "for i in range(len(points)):           # draw circles on the river mouths?\n",
    "    cv.circle(img2,tuple(np.flip(points[i])), int((img.shape[0] / 512) * 10), (255,0,0),-1)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Borrowed , all of it\n",
    "def segments_distance(a,b,c,d):\n",
    "  \"\"\" distance between two segments in the plane:\n",
    "      one segment is a to b\n",
    "      the other is   c to d\n",
    "  \"\"\"\n",
    "  #print(a[0],a[1],b[0],b[1],c[0],c[1],d[1],d[0])\n",
    "  #print(segments_distance_internal(a[0],a[1],b[0],b[1],c[0],c[1],d[1],d[0]))\n",
    "  return segments_distance_internal(a[0],a[1],b[0],b[1],c[0],c[1],d[0],d[1])\n",
    "\n",
    "def segments_distance_internal(x11, y11, x12, y12, x21, y21, x22, y22):\n",
    "  \"\"\" distance between two segments in the plane:\n",
    "      one segment is (x11, y11) to (x12, y12)\n",
    "      the other is   (x21, y21) to (x22, y22)\n",
    "  \"\"\"\n",
    "  if segments_intersect(x11, y11, x12, y12, x21, y21, x22, y22): return 0\n",
    "  # try each of the 4 vertices w/the other segment\n",
    "  distances = []\n",
    "  distances.append(point_segment_distance(x11, y11, x21, y21, x22, y22))\n",
    "  distances.append(point_segment_distance(x12, y12, x21, y21, x22, y22))\n",
    "  distances.append(point_segment_distance(x21, y21, x11, y11, x12, y12))\n",
    "  distances.append(point_segment_distance(x22, y22, x11, y11, x12, y12))\n",
    "  return min(distances)\n",
    "\n",
    "def segments_intersect(x11, y11, x12, y12, x21, y21, x22, y22):\n",
    "  \"\"\" whether two segments in the plane intersect:\n",
    "      one segment is (x11, y11) to (x12, y12)\n",
    "      the other is   (x21, y21) to (x22, y22)\n",
    "  \"\"\"\n",
    "  dx1 = x12 - x11\n",
    "  dy1 = y12 - y11\n",
    "  dx2 = x22 - x21\n",
    "  dy2 = y22 - y21\n",
    "  delta = dx2 * dy1 - dy2 * dx1\n",
    "  if delta == 0: return False  # parallel segments\n",
    "  s = (dx1 * (y21 - y11) + dy1 * (x11 - x21)) / delta\n",
    "  t = (dx2 * (y11 - y21) + dy2 * (x21 - x11)) / (-delta)\n",
    "  return (0 <= s <= 1) and (0 <= t <= 1)\n",
    "\n",
    "import math\n",
    "# I think this finds the distance between a point and a line segment\n",
    "def point_segment_distance(px, py, x1, y1, x2, y2):\n",
    "  dx = x2 - x1\n",
    "  dy = y2 - y1\n",
    "  if dx == dy == 0:  # the segment's just a point\n",
    "    return math.hypot(px - x1, py - y1)\n",
    "\n",
    "  # Calculate the t that minimizes the distance.\n",
    "  t = ((px - x1) * dx + (py - y1) * dy) / (dx * dx + dy * dy)\n",
    "\n",
    "  # See if this represents one of the segment's\n",
    "  # end points or a point in the middle.\n",
    "  if t < 0:\n",
    "    dx = px - x1\n",
    "    dy = py - y1\n",
    "  elif t > 1:\n",
    "    dx = px - x2\n",
    "    dy = py - y2\n",
    "  else:\n",
    "    near_x = x1 + t * dx\n",
    "    near_y = y1 + t * dy\n",
    "    dx = px - near_x\n",
    "    dy = py - near_y\n",
    "\n",
    "  return math.hypot(dx, dy)\n",
    "\n",
    "def point_segment_distance_tuple(p,a,b):\n",
    "        return point_segment_distance(p[0],p[1],a[0],a[1],b[0],b[1])\n",
    "    \n",
    "def segments_intersect_tuple(a1,a2,b1,b2):\n",
    "    return segments_intersect(a1[0],a1[1],a2[0],a2[1],b1[0],b1[1],b2[0],b2[1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNode(pointInspace,Priority):\n",
    "    global nodecounter\n",
    "    global nodes\n",
    "    global candidates\n",
    "    global G\n",
    "    global Gkd\n",
    "    nodes.append(nodecounter)\n",
    "    candidates.append(nodecounter)\n",
    "    G.add_node(nodecounter,pos=(pointInspace[0],pointInspace[1]),elevation=pointInspace[2],priority=Priority,rosgen='',flow=0) ## XYZ of initial node, on the border, should be at some threshold above sea level\n",
    "    nodecounter+=1\n",
    "    allpoints_list = [[G.nodes[x]['pos'][0],G.nodes[x]['pos'][1]] for x in nodes]\n",
    "    allpoints_nd = np.array(allpoints_list)\n",
    "    Gkd = cKDTree(allpoints_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## make river mouths into nodes and add them to candidates for expansion\n",
    "for i in range(len(points)):\n",
    "    mouthnodes.append(nodecounter)\n",
    "    addNode((points[i][1],points[i][0],0),random.randint(1,N_majorRivers)) #1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectNode(candidate_nodes,zeta):\n",
    "\n",
    "    lowestCandidateZ = min([G.nodes[i]['elevation'] for i in candidate_nodes])\n",
    "#    for i in range(len(candidate_nodes)):\n",
    "#        z=G.nodes[candidate_nodes[i]]['elevation']\n",
    "#        lowestCandidateZ = min(z,lowestCandidateZ);\n",
    "    subselection = [n for n in candidate_nodes if G.nodes[n]['elevation'] < lowestCandidateZ+zeta ]\n",
    "#    for node in candidate_nodes:\n",
    "#            z=G.nodes[node]['elevation']\n",
    "#            if z < lowestCandidateZ+zeta:\n",
    "#               subselection.append(node)\n",
    "\n",
    "    subselection.sort(key = lambda r : G.nodes[r]['priority'],reverse = True)\n",
    "    subsubselection=[i for i in subselection if G.nodes[i]['priority'] == G.nodes[subselection[0]]['priority']]\n",
    "#    for i in range(len(subselection)):\n",
    "#        if G.nodes[subselection[i]]['priority'] == G.nodes[subselection[0]]['priority']:\n",
    "#            subsubselection.append(subselection[i])\n",
    "    idxOfLowestCandidateZ =[G.nodes[i]['elevation'] for i in subsubselection].index(min([G.nodes[i]['elevation'] for i in subsubselection])) \n",
    "    \n",
    "    return subsubselection[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(priority,node):         # alpha, as in the expansion rules in Table 1\n",
    "    if priority==1:\n",
    "        ruleBase(priority,node)\n",
    "    else:\n",
    "        Pval = random.random();\n",
    "        if Pval <= Pa:\n",
    "            rulePa(priority,node)\n",
    "        elif Pval <= Pa+Pc:\n",
    "            rulePc(priority,node)\n",
    "        else:\n",
    "            rulePs(priority,node)\n",
    "\n",
    "            \n",
    "def ruleBase(priority,node): #filling\n",
    "    #tao(priority,node)\n",
    "    for i in range(random.randint(1,5)):\n",
    "        beta(priority,node)\n",
    "        \n",
    "        \n",
    "def rulePc(priority,node): #rive growth\n",
    "    #tao(priority,node)\n",
    "    beta(priority,node)\n",
    "    \n",
    "    \n",
    "def rulePs(priority,node): #symetric junction\n",
    "    #tao(priority,node)\n",
    "    beta(priority-1,node)\n",
    "    beta(priority-1,node)\n",
    "\n",
    "    \n",
    "def rulePa(priority,node): # asymetric junction\n",
    "    #tao(priority,node)\n",
    "    beta(priority,node)\n",
    "    beta(random.randint(1,priority-1),node)\n",
    "    \n",
    "    \n",
    "def beta(priority,node):\n",
    "    possiblenewones = picknewnodepos(node)\n",
    "    if len(possiblenewones)>0:\n",
    "        point = possiblenewones[random.randint(0,len(possiblenewones)-1)]\n",
    "        slope = 2.0 * riverSlope[ int(G.nodes[node]['pos'][0]) , int(G.nodes[node]['pos'][1])] / 255\n",
    "        newZ = G.nodes[node]['elevation'] + random.randint(1, int(1 + slopeRate * slope))\n",
    "        addNode((point[1],point[0],newZ),priority)\n",
    "        G.add_edge(node,nodes[-1]) ## XYZ of initial node, on the border, should be at some threshold above sea level\n",
    "    else:\n",
    "        tao(priority,node)\n",
    "\n",
    "\n",
    "def tao(priority,node):\n",
    "    try:\n",
    "        candidates.remove(node)\n",
    "    except:\n",
    "        None\n",
    "    finally:\n",
    "        None\n",
    "        \n",
    "        \n",
    "def picknewnodepos(parentnode): # I think this chooses a location for a candidate node\n",
    "    s= datetime.datetime.now()\n",
    "    \n",
    "    pos = [G.nodes[parentnode]['pos'][1],G.nodes[parentnode]['pos'][0]] # position of parent node\n",
    "    sx=max(0,pos[0]-edgeLength)                                         # shifts the position up-left by edgeLength\n",
    "    sy=max(0,pos[1]-edgeLength)                                         # \"      \"   \"        \"  \"    \"  \"\n",
    "    # Basically, this is a 2-D array, a subset of imgray of pixels that are edgeLength around the parent node's\n",
    "    # position. imgray is the outline image, so the array's contents are basically 255 inicating land, and 0\n",
    "    # indicating seeee\n",
    "    sub = imgray[sx:min(imgray.shape[0],pos[0]+edgeLength),sy:min(imgray.shape[1],pos[1]+edgeLength)]\n",
    "    # This is a mask of sub, but only land\n",
    "    domain = np.argwhere(sub>0) # pixels relative to pos-(sx,sy)\n",
    "    # A boolean mask, indicating pixels that are edgeLength away\n",
    "    # This guy knows his way around a linear algebra library\n",
    "    withinEdistance  = np.floor(np.linalg.norm(domain+(sx-pos[0],sy-pos[1]),axis=1))==edgeLength\n",
    "    \n",
    "    # I think this eliminates pixels that are too close to the coast\n",
    "    atEdistanceFromNode = domain[withinEdistance] # pixels that are at edge distance form the parent node\n",
    "    awayfromGamma=[]\n",
    "    a=datetime.datetime.now()\n",
    "    print(\"pa:\",a-s)\n",
    "    for p in atEdistanceFromNode:\n",
    "        aa=p+(sx,sy)\n",
    "        dist_gamma =cv.pointPolygonTest(contour,(aa[0],aa[1]),True)\n",
    "        if abs(dist_gamma)>eta*edgeLength:\n",
    "            awayfromGamma.append((aa[0],aa[1]))\n",
    "    edgeCleared = awayfromGamma.copy()\n",
    "    b=datetime.datetime.now()\n",
    "    print(\"pb:\",b-a)\n",
    "    \n",
    "    # I think this tries to pick a location that is far from neighboring nodes\n",
    "    for i in range(len(awayfromGamma)): # for each pixel that is sufficiantly distant from the coast\n",
    "        p = awayfromGamma[i]\n",
    "        # nodes that are within 2*edgeLength of the prospect pixel\n",
    "        nodesToCheck=Gkd.query_ball_point((p[1],p[0]),2*edgeLength)\n",
    "        myedges=[G.out_edges(n) for n in nodesToCheck] # all edges upstream of nodes that are nearby\n",
    "        myedges = [item for edges in myedges for item in edges] # I think this looks for the nodes that these edges point to\n",
    "        for j in range(len(myedges)):\n",
    "                e= myedges[j]\n",
    "                # distance to the other river\n",
    "                dist = point_segment_distance(p[1],p[0],G.nodes[e[0]]['pos'][0],G.nodes[e[0]]['pos'][1],G.nodes[e[1]]['pos'][0],G.nodes[e[1]]['pos'][1])\n",
    "                if dist<edgeLength*sigma:\n",
    "                    l1 = len(edgeCleared)\n",
    "                    edgeCleared.remove(p)\n",
    "                    assert(len(edgeCleared)<l1)\n",
    "                    break\n",
    "    c=datetime.datetime.now()\n",
    "    print(\"pc:\",c-b)\n",
    "    print(f\"Possible New Locations: {len(edgeCleared)}\")\n",
    "    return edgeCleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesToCheck=[0,1]\n",
    "myedges=[e for e in [G.out_edges(n) for n in nodesToCheck]]\n",
    "print(nodesToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateHorton_Strahler(selectedCandidate):\n",
    "    #find the leafs from this node and calculate upstream\n",
    "    leafs = [s for s in nx.descendants(G,selectedCandidate) if len(G.out_edges(s))==0]\n",
    "    workingqueue=leafs\n",
    "    nextQueue=set()\n",
    "    while len(workingqueue)>0:\n",
    "        nextQueue=set()\n",
    "        for i in range(len(workingqueue)):\n",
    "            priority=1\n",
    "            children = G.successors(workingqueue[i])\n",
    "            ChildrenPriorities = [G.nodes[x]['priority'] for x in children]\n",
    "            if len(ChildrenPriorities)>0:\n",
    "                priority = max(ChildrenPriorities)\n",
    "                if ChildrenPriorities.count(priority)>1:\n",
    "                    priority=priority+1\n",
    "            G.nodes[workingqueue[i]]['priority']=priority;\n",
    "            parent = G.predecessors(workingqueue[i])\n",
    "            parent=[x for x in parent]\n",
    "            if len(parent)==1:\n",
    "                nextQueue.add(parent[0])\n",
    "        workingqueue=list(nextQueue)    \n",
    "\n",
    "\n",
    "def calculateHorton_Strahler_():\n",
    "    leafs = [x for x in G.nodes() if G.out_degree(x)==0]\n",
    "    workingqueue=leafs\n",
    "    nextQueue=set()\n",
    "    while len(workingqueue)>0:\n",
    "        nextQueue=set()\n",
    "        for i in range(len(workingqueue)):\n",
    "            priority=1\n",
    "            children = G.successors(workingqueue[i])\n",
    "            ChildrenPriorities = [G.nodes[x]['priority'] for x in children]\n",
    "            if len(ChildrenPriorities)>0:\n",
    "                priority = max(ChildrenPriorities)\n",
    "                if ChildrenPriorities.count(priority)>1:\n",
    "                    priority=priority+1\n",
    "            G.nodes[workingqueue[i]]['priority']=priority;\n",
    "            parent = G.predecessors(workingqueue[i])\n",
    "            parent=[x for x in parent]\n",
    "            if len(parent)==1:\n",
    "                nextQueue.add(parent[0])\n",
    "        workingqueue=list(nextQueue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I think this is where the rivers are built\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "while len(candidates)!=0:\n",
    "    s= datetime.datetime.now()\n",
    "    selectedCandidate = selectNode(candidates,zeta)\n",
    "    a=datetime.datetime.now()\n",
    "    alpha(G.nodes[selectedCandidate]['priority'],selectedCandidate)\n",
    "    b=datetime.datetime.now()\n",
    "    calculateHorton_Strahler(selectedCandidate)\n",
    "    c=datetime.datetime.now()\n",
    "    clear_output(wait=True)\n",
    "    print(\"Select:   \",a-s) # time it takes to select a node\n",
    "    print(\"Expand:   \",b-a) # time it takes to expand the node\n",
    "    print(\"Classify: \",c-b) # time it takes to calculate the Horton-Strahler classification of the node\n",
    "    print(len(nodes))  # use display(f) if you encounter performance issues\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this looks for nodes that may be too close together\n",
    "\n",
    "nodesToCheck=Gkd.query_ball_point(G.nodes[0]['pos'],2*edgeLength)\n",
    "myedges=[G.out_edges(n) for n in nodesToCheck]\n",
    "myedges = [item for edges in myedges for item in edges]\n",
    "print(nodesToCheck)\n",
    "print(myedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I don't think this segment runs\n",
    "\n",
    "plt.figure(num=None, figsize=(16, 16), dpi=80)\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "plt.imshow(img2)\n",
    "#labels = list(map(lambda x: G.nodes[x]['priority'],nodes))\n",
    "labels = list(map(lambda x: x,nodes))\n",
    "labels = dict(zip(nodes,labels))\n",
    "#nx.draw_networkx_labels(G,pos)\n",
    "nx.draw(G,pos,node_size=60,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgvoronoi = np.zeros(imgray.shape,dtype=np.uint16)                # zeroes in the shape of the input image\n",
    "imgRiverHeights = np.zeros(imgray.shape,dtype=np.uint16)\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "points=[G.nodes[x]['pos'] for x in nodes]\n",
    "points.append((0,0))                                               # adds points of the 4 corners of the image\n",
    "points.append((0,img2.shape[1]))\n",
    "points.append((img2.shape[0],0))\n",
    "points.append((img2.shape[0],img2.shape[1]))\n",
    "\n",
    "vor = Voronoi(points,qhull_options=\"Qbb Qc Qz Qx\")                 # qhull options for the qhull library\n",
    "\n",
    "pos=nx.get_node_attributes(G,'pos')                                # gets the 'pos' attributes of all nodes\n",
    "#labels = list(map(lambda x: G.nodes[x]['priority'],nodes))\n",
    "labels = list(map(lambda x: x,nodes))                              # I think these two lines make a dictionary\n",
    "labels = dict(zip(nodes,labels))                                   # that associates each node with a label\n",
    "#nx.draw_networkx_labels(G,pos)\n",
    "'''\n",
    "fig=voronoi_plot_2d(vor,line_colors='red')\n",
    "fig.set_size_inches(16, 16, forward=True)\n",
    "fig.set_dpi(80)\n",
    "plt.imshow(img2,aspect='auto')\n",
    "fig.set_tight_layour(True)\n",
    "'''\n",
    "ret, thresh = cv.threshold(imgray, 127, 1, 0)\n",
    "mask = np.array(thresh, dtype=np.uint16)\n",
    "mask*=(256*256-1)\n",
    "voroniCount=1\n",
    "for n in nodes:\n",
    "    ridx=vor.point_region[n]  # index of the region the node is in\n",
    "    if ridx==-1:              # if ridx is -1, then the node is not there, so skip this\n",
    "        continue\n",
    "    r = vor.regions[ridx]     # gets the indicies of the points forming the shape around the node\n",
    "    debp = [vor.vertices[x].astype(int) for x in r if x!=-1] # creates a list of the node's vertices as integers\n",
    "    debp = np.array( [ [ x[0],x[1] ] for x in debp] )   # recreates the list in a shape that cv can understand\n",
    "    cv.fillPoly(imgvoronoi,[debp],np.int16(ridx+1).item()) # fills the voronoi polygon with the region index?\n",
    "    cv.fillPoly(imgRiverHeights,[debp],np.int16(G.nodes[n]['elevation']).item())\n",
    "    voroniCount+=1\n",
    "\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img2)\n",
    "ylim=ax.get_ylim();\n",
    "xlim=ax.get_xlim();\n",
    "nx.draw(G,pos,node_size=60,labels=labels,ax=ax)\n",
    "voronoi_plot_2d(vor, point_size=10, ax=ax,line_colors=['yellow']) # draws the voronoi cells?\n",
    "ax.set_ylim(ylim);\n",
    "ax.set_xlim(xlim);\n",
    "kernel = cv.getStructuringElement(cv.MORPH_RECT,(2,2))\n",
    "plt.show()\n",
    "print(\"Color proportional to cell index\")\n",
    "plt.imshow(imgvoronoi)\n",
    "imgvoronoi = cv.bitwise_and(imgvoronoi,mask)\n",
    "\n",
    "plt.show()\n",
    "print(\"Same as last image but with the mask applied\")\n",
    "plt.imshow(imgvoronoi)\n",
    "\n",
    "plt.show()\n",
    "print(\"Shape mask\")\n",
    "plt.imshow(mask)\n",
    "\n",
    "plt.show()\n",
    "print('River Elevations')\n",
    "plt.imshow(imgRiverHeights)\n",
    "\n",
    "### Breakdown of the image\n",
    "# Giant red circles identify river mouths\n",
    "# Blue dots identify river nodes\n",
    "# Black arrows point upstream\n",
    "# Black numbers identify the order of the nodes\n",
    "# Green outline identifies the coast\n",
    "# Yellow lines outline the voronoi cells around each river node\n",
    "# Yellow dots identify the vertices of the voronoi cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.unique(imgvoronoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voronoiimg has the watersheds where pixels of value  centernodeidx + 1 are pixels that belong to watershed of node centernodeidx, since there is only one s for each node ( that is the incoming edge from the parent ), we can calculate the watershed areas and store them into each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate watershed areas\n",
    "for node in nodes:\n",
    "    pos = G.nodes[node]['pos']\n",
    "    pixelVal = imgvoronoi[pos[1]][pos[0]]\n",
    "    area = np.count_nonzero(imgvoronoi==pixelVal)\n",
    "    G.nodes[node]['localwatershedarea']=area\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total area of the watershed behind the node\n",
    "# also calculate the flow through the node\n",
    "for node in nx.dfs_postorder_nodes(G):  # search nodes in a depth-first post-ordering manner\n",
    "    localWatershed = G.nodes[node]['localwatershedarea']\n",
    "    Watershed =localWatershed+ sum([G.nodes[src]['inheritedwatershed'] for src in G.successors(node)])\n",
    "    G.nodes[node]['inheritedwatershed']=Watershed                         # calculate total watershed area\n",
    "    G.nodes[node]['flow'] =0.42*G.nodes[node]['inheritedwatershed']**0.69 # calculate river flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Voronoi vertex v1,v2 accesses pixelvalue of img at [v2,v1]\n",
    "# calcualte Zs of Qs, for each q its the max of the input nodes that has q in its region, plus a random margin\n",
    "\n",
    "### Explainer\n",
    "# The Qs are the vertices of the voronoi cells\n",
    "# I think that \"Zs of Qs\" refers to the altitudes of those vertices\n",
    "\n",
    "# Parallel arrays are bad practice. This must be reformed\n",
    "qz={} # elevation \n",
    "qd={} # distance between q and the node\n",
    "ql={} # location (x,y) of each point\n",
    "for n in nodes:                    # loop through all nodes (obviously)\n",
    "    r=vor.point_region[n]\n",
    "    if r==-1:\n",
    "        continue\n",
    "    for vertex in vor.regions[r]:  # loop through all the vertices of the voronoi cell around the node\n",
    "        #print(n,r,vertex,vor.vertices[vertex])\n",
    "        if  not(0<= int(vor.vertices[vertex][0]) < (imgray.shape[0] - 5) and 0<= int(vor.vertices[vertex][1]) < (imgray.shape[1] - 1)) :\n",
    "            #print(f'x: {vor.vertices[vertex][0]} y: {vor.vertices[vertex][1]}')\n",
    "            continue ## ignore vertices outside of the image\n",
    "        #print(vertex)\n",
    "        if vertex not in qz: # ignore vertices that have already been processed\n",
    "            qz[vertex]=0\n",
    "            #print(vertex)\n",
    "            #print(f'x: {vor.vertices[vertex][0]} y: {vor.vertices[vertex][1]}')\n",
    "            slope = terrainSlope[int(vor.vertices[vertex][0]), int(vor.vertices[vertex][1])] / 255\n",
    "                         # I'm pretty sure that 'norm' just means 'distance', in this case\n",
    "                                                    # position of the vertex relative to the node\n",
    "                                                # coordinates of the vertex     # coordinates of the node\n",
    "            qd[vertex] = int(np.linalg.norm( vor.vertices[vertex].astype(int) - G.nodes[n]['pos'])) # + G.nodes[n]['elevation'])\n",
    "        qz[vertex ]= max(qz[vertex],G.nodes[n]['elevation']) # (generally) sets the elevation to the node's elevation\n",
    "\n",
    "        # creates a list of coordinates for the vertices in the region\n",
    "        # is this used _anywhere_ else?\n",
    "        qs = [vor.vertices[x].astype(int) for x in vor.regions[n] if x!=-1]\n",
    "        \n",
    "        # This is used in the terrain slope function\n",
    "        ql[vertex] = vor.vertices[vertex]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All this does is increase the altitude of\n",
    "# those voronoi vertices by a random amount\n",
    "for q in qz:\n",
    "    slope = terrainSlope[int(ql[q][0]), int(ql[q][1])] / 255\n",
    "    #qz[q]*=slope\n",
    "    #pass\n",
    "    qz[q]+= int((random.uniform(0,5) *qd[q]) * slope) # TODO terrain slope map\n",
    "    #qz[q]+=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qvals = [imgray[int(vertex[1]),int(vertex[0])] for vertex in vor.vertices if  0<=  vertex[0] < imgray.shape[0] and 0<=  vertex[1] < imgray.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(Node):\n",
    "    # Based on river slope and distance from Gamma\n",
    "    # TODO: A real classification\n",
    "    es = G.out_edges(Node)\n",
    "    es = list(es)\n",
    "    for e in es:\n",
    "        grade=(G.nodes[e[1]]['elevation']-G.nodes[e[0]]['elevation'])/edgeLength\n",
    "        if grade > 0.1:\n",
    "            G.nodes[e[1]]['rosgen']='A+'\n",
    "        elif grade >0.04:\n",
    "            G.nodes[e[1]]['rosgen']='A'\n",
    "        elif grade > 0.02:\n",
    "            G.nodes[e[1]]['rosgen']=['G','D','B'][random.randint(0,2)];\n",
    "        elif grade > 0.005:\n",
    "            G.nodes[e[1]]['rosgen']=['C','D','E','F'][random.randint(0,3)];\n",
    "        else :\n",
    "            G.nodes[e[1]]['rosgen']='DA'\n",
    "            \n",
    "from itertools import islice\n",
    "\n",
    "def window(seq, n=2): ##Borrowed as is\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "        \n",
    "def clean_asin(sinAngle): ## Borrowed but modified\n",
    "    return math.asin(min(1,max(sinAngle,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    classify(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remebmer: incoming edges are downstream; outgoing edges are upstream\n",
    "#Create confluences, to do that, sort the outgoing edges(these are the inlets to the node) by the angle they form with the node\n",
    "import math\n",
    "for n in nodes:\n",
    "    es = G.out_edges(n)\n",
    "    ie = G.in_edges(n)\n",
    "    \n",
    "    # There ought to be a single incoming (downstream) edge unless it is a mouth.\n",
    "    # Otherwise, there ought to be one, and no more\n",
    "    if len(list(ie))==0:\n",
    "        continue\n",
    "    assert( (len(list(ie))==1 ))\n",
    "    \n",
    "    ie = list(ie)[0]\n",
    "    vRef = np.subtract(G.nodes[ie[1]]['pos'],G.nodes[ie[0]]['pos'])\n",
    "    vRef = vRef / np.linalg.norm(vRef)\n",
    "    \n",
    "    # sorts the outgoing (upstream) edges by the angle they form with the node\n",
    "    es = list(es);\n",
    "    es.sort(key = lambda r : clean_asin((np.cross(np.subtract(G.nodes[r[1]]['pos'],G.nodes[r[0]]['pos'])/np.linalg.norm(np.subtract(G.nodes[r[1]]['pos'],G.nodes[r[0]]['pos'])),vRef))),reverse = True)\n",
    "    # es now contains edges sorted by the angle they form with the source vector\n",
    "    wes = window(es)\n",
    "    #print(es)\n",
    "    #for upstream in wes:\n",
    "        # create junctions\n",
    "    #    print(upstream[0],upstream[1])\n",
    "    \n",
    "    # I didn't bother to make sense of this, but I guess this is where confluences are created\n",
    "    ks=[]\n",
    "    for e in wes:\n",
    "        angle = random.uniform(0,10)\n",
    "        if G.nodes[e[0][1]]['priority']!=G.nodes[e[1][1]]['priority']:\n",
    "            angle+=80\n",
    "        ks+=[angle]\n",
    "    \n",
    "    lastconfluence=None\n",
    "    if len(ks)==0:\n",
    "        # connect the only upstream node to the outlet\n",
    "        None\n",
    "    else:\n",
    "        # create confluence between memebers of ks, then connect last confluence to outlet\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is a node graph, like the voronoi graph earlier. But the arrows are weighted by flow\n",
    "\n",
    "plt.figure(num=None, figsize=(16, 16), dpi=80)\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "plt.imshow(img2)\n",
    "#labels = list(map(lambda x: G.nodes[x]['priority'],nodes))\n",
    "labels = list(map(lambda x: x,nodes))\n",
    "labels = dict(zip(nodes,labels))\n",
    "#nx.draw_networkx_labels(G,pos)\n",
    "normalizer =max([G.nodes[u]['flow'] for u in nodes]) \n",
    "weights = [6*G.nodes[u]['flow']/normalizer for u,v in G.edges]\n",
    "\n",
    "#nx.draw(G,pos,node_size=10,labels=labels,width=weights)\n",
    "nx.draw(G,pos,node_size=0,width=weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a map of rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the least intuitive way to calculate Euclidean distance, but I respect it\n",
    "def distance(a,b):\n",
    "   return np.linalg.norm( np.subtract(a , b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just gets the highest elevation in the entire map\n",
    "\n",
    "maxNodeElevation = max([G.nodes[n]['elevation'] for n in nodes])\n",
    "print(f'Highest Node: {maxNodeElevation}')\n",
    "maxqElevation = max(qz.values())\n",
    "print(f'Highest Ridge Elevation: {maxqElevation}')\n",
    "maxZ = max([maxNodeElevation,maxqElevation])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Same thing, but over imgvoronoi instead of the map\n",
    "\n",
    "plt.figure(num=None, figsize=(16, 16), dpi=80)\n",
    "pos=nx.get_node_attributes(G,'pos')\n",
    "plt.imshow(imgRiverHeights)\n",
    "labels = list(map(lambda x: x,nodes))\n",
    "labels = dict(zip(nodes,labels))\n",
    "normalizer =max([G.nodes[u]['flow'] for u in nodes]) \n",
    "weights = [6*G.nodes[u]['flow']/normalizer for u,v in G.edges]\n",
    "\n",
    "nx.draw(G,pos,node_size=60,labels=labels,width=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Borrowed, heavily modified\n",
    "from poisson import PoissonGenerator\n",
    "\n",
    "disk = False                # this parameter defines if we look for Poisson-like distribution on a disk/sphere (center at 0, radius 1) or in a square/box (0-1 on x and y)\n",
    "repeatPattern = True        # this parameter defines if we look for \"repeating\" pattern so if we should maximize distances also with pattern repetitions\n",
    "num_points = 50              # number of points we are looking for\n",
    "num_iterations = 4          # number of iterations in which we take average minimum squared distances between points and try to maximize them\n",
    "first_point_zero = disk     # should be first point zero (useful if we already have such sample) or random\n",
    "iterations_per_point = 128  # iterations per point trying to look for a new point with larger distance\n",
    "sorting_buckets = 0         # if this option is > 0, then sequence will be optimized for tiled cache locality in n x n tiles (x followed by y)\n",
    "num_dim = 2                 # 1, 2, 3 dimensional version\n",
    "num_rotations = 1           # number of rotations of pattern to check against\n",
    "\n",
    "allteepoints = []         # Tee is a terrain primitive\n",
    "taos_for_regions = {}     # I have no idea what this is\n",
    "poisson_generator = PoissonGenerator( repeatPattern, first_point_zero)\n",
    "points = poisson_generator.find_point_set(num_points, num_iterations, iterations_per_point, num_rotations)\n",
    "for n in nodes:\n",
    "    r = vor.regions[vor.point_region[n]]\n",
    "    ridge_positions = { x:(vor.vertices[x].astype(int)[0],vor.vertices[x].astype(int)[1]) for x in r if x!=-1 }\n",
    "    reg = list(ridge_positions.values()) # converts ridge_positions from a dictionary to a list of tuples (coordinates)\n",
    "    rreg = [[x[0],x[1]] for x in reg]    # converts reg from a list of tuples to a 2-D array\n",
    "    rreg= np.array(rreg)                 # converts again, using numpy\n",
    "    idxes = np.where(imgvoronoi==vor.point_region[n]+1) # coordinates of all pixels in the voronoi region\n",
    "    xllim = min(x for x in idxes[0]) # these lines get the bounding box of the voronoi region\n",
    "    xulim = max(x for x in idxes[0])\n",
    "    yllim = min(x for x in idxes[1])\n",
    "    yulim = max(x for x in idxes[1])\n",
    "    \n",
    "    # I don't know why he creates another bounding box with opencv\n",
    "    b= np.array([[xllim,yllim],[xllim,yulim],[xulim,yllim],[xulim,yulim]])\n",
    "    b=cv.minAreaRect(b)\n",
    "    pts = cv.boxPoints(b)\n",
    "    xllim = int(min(x[0] for x in pts))\n",
    "    xulim = int(max(x[0] for x in pts))\n",
    "    yllim = int(min(x[1] for x in pts))\n",
    "    yulim = int(max(x[1] for x in pts))\n",
    "    \n",
    "    # I think this applies a mask to the poisson points, and adds those points as Tees for the cell\n",
    "    points_projected = [ [int(p[0]*(yulim-yllim)+yllim),int(p[1]*(xulim-xllim)+xllim)] for p in points]\n",
    "    points_filtered = [ (p[0],p[1]) for p in points_projected if imgvoronoi[p[1]][p[0]]==vor.point_region[n]+1 ]\n",
    "    allteepoints+=points_filtered\n",
    "    \n",
    "    # I'm not sure what this does\n",
    "    taos_for_regions[vor.point_region[n]]=points_filtered\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(n,\" out of \",len(nodes))  # use display(f) if you encounter performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,16))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(imgvoronoi)\n",
    "ax.scatter(*zip(*allteepoints), color='r', alpha=0.6, lw=0)\n",
    "\n",
    "ylim=ax.get_ylim();\n",
    "xlim=ax.get_xlim();\n",
    "nx.draw(G,pos,node_size=60,labels=labels,ax=ax)\n",
    "voronoi_plot_2d(vor, point_size=10, ax=ax,line_colors=['yellow'])\n",
    "\n",
    "ax.set_ylim(ylim);\n",
    "ax.set_xlim(xlim);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(p,u,v):\n",
    "    n = np.subtract(u,v)\n",
    "    nnorm = np.linalg.norm(n, 2)\n",
    "    n = n/nnorm\n",
    "    ret = np.dot(np.subtract(p,v), n)\n",
    "    proj = ret/nnorm\n",
    "    if proj >1 :\n",
    "        proj=1\n",
    "    if proj <0 :\n",
    "        proj =0\n",
    "    return proj*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shapely.geometry as geom\n",
    "import numpy as np\n",
    "from shapely.geometry import asLineString\n",
    "\n",
    "point = geom.Point(0.8, 10.5)\n",
    "\n",
    "# Note that \"line.distance(point)\" would be identical\n",
    "\n",
    "# This is a dictionary of nodes. I think it stores\n",
    "# the path to the sea for each node\n",
    "rivers = {}\n",
    "\n",
    "for n in mouthnodes:\n",
    "    # remember that out_edges gets upstream nodes\n",
    "    leaves = [s for s in nx.descendants(G,n) if len(G.out_edges(s))==0]\n",
    "    for leaf in leaves: # essentially, this loops through all the highest nodes of a particular mouth\n",
    "        path = nx.shortest_path(G,n,leaf) # path to the leaf (there's only one, so it's the shortest)\n",
    "\n",
    "        x = np.array([G.nodes[p]['pos'][0] for p in path])\n",
    "        y = np.array([G.nodes[p]['pos'][1] for p in path])\n",
    "        z = np.array([G.nodes[p]['elevation'] for p in path])\n",
    "        \n",
    "        # it seems to me that, if the path is short, this block\n",
    "        # adjusts the positions of the first three nodes\n",
    "        if len(x)<4:\n",
    "            x1 = (x[0]+x[1])/2\n",
    "            x2 = (x[0]+x1)/2\n",
    "            y1 = (y[0]+y[1])/2\n",
    "            y2 = (y[0]+y1)/2\n",
    "            z1 = (z[0]+z[1])/2\n",
    "            z2 = (z[0]+z1)/2\n",
    "            tmp = x[1:]\n",
    "            x = [x[0],x2,x1]+list(tmp)\n",
    "            x = np.array(x)\n",
    "            tmp=y[1:]\n",
    "            y = [y[0],y2,y1]+list(tmp)\n",
    "            y = np.array(y)\n",
    "            tmp=z[1:]\n",
    "            z = [z[0],z2,z1]+list(tmp)\n",
    "            z = np.array(z)\n",
    "        \n",
    "        # I think that this is where the river paths are smoothed\n",
    "        tck, u = interpolate.splprep([x, y,z], s=0)\n",
    "        unew = np.arange(0, 1.01, 0.05)\n",
    "        out = interpolate.splev(unew, tck)\n",
    "        \n",
    "        lstr=[] # lstr is apparently \"line string\"\n",
    "        dbg=[] # I think this is to verify that altitude increases continually\n",
    "        for i in range(len(out[0])): # loops through each coordinate created in interpolation\n",
    "            lstr.append((out[0][i],out[1][i],int(out[2][i])))\n",
    "            dbg.append(int(out[2][i]))\n",
    "        line = asLineString(lstr)\n",
    "        \n",
    "        for p in path: # for each node in the path to this particular leaf\n",
    "            # I'm pretty sure this loop ensures that\n",
    "            # the path to the sea is up to date\n",
    "            if p in rivers:\n",
    "                rivers[p].append(line)\n",
    "            else:\n",
    "                rivers[p]=[line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO:Calculate Zees for Cees of Tees ( Elevations of center points of terrain primitives)\n",
    "\n",
    "czs = {}\n",
    "for t in allteepoints:\n",
    "    i = t[1] # x\n",
    "    j = t[0] # y\n",
    "    ridx = imgvoronoi[i][j]-1 # the region id that the point is in\n",
    "    r = vor.regions[ridx]     # the vertices of the voronoi cells\n",
    "    ridge_positions = { x:(vor.vertices[x].astype(int)[0],vor.vertices[x].astype(int)[1]) for x in r if x!=-1 and 0<=  vor.vertices[x].astype(int)[0] < imgray.shape[0] and 0<=  vor.vertices[x].astype(int)[1] < imgray.shape[1]}\n",
    "    #ridge_positions = np.array([[x[0],x[1]] for x in verts_in_r if 0<=  x[0] < imgray.shape[0] and 0<=  x[1] < imgray.shape[1]]) \n",
    "    ridge_elevations = { x:qz[x] for x in r if x  in qz }\n",
    "    r_refined = list(ridge_positions.keys())\n",
    "    #find closest ridge point\n",
    "    closestR =r_refined[[distance((j,i),ridge_positions[x]) for x in r_refined].index(min([distance((j,i),ridge_positions[x]) for x in r_refined]))]\n",
    "    elevationAtClosestR = ridge_elevations[closestR]\n",
    "    dist_gamma =cv.pointPolygonTest(contour,(i,j),True) # distance to Gamma (the coast? or the river?)\n",
    "    distanceFromR = distance((j,i),ridge_positions[closestR]) # distance to closest ridge point\n",
    "    if(dist_gamma<distanceFromR): # if the coast is closer than the closest ridge, then...\n",
    "        distanceFromR = dist_gamma\n",
    "        elevationAtClosestR= 0 #10 # I guess this is the elevation at the coast\n",
    "    #point.distance(rivers[n])\n",
    "    point = geom.Point(j,i) # creates an instance of the Geometry package point class\n",
    "    nodeOfregion = list(vor.point_region).index(ridx)\n",
    "    \n",
    "    projected = None # this ought to be the location of the river node (should use rdix)\n",
    "    distancefromN = None # this ought to be the distance to that node\n",
    "    if nodeOfregion in rivers:\n",
    "        local_rivers = rivers[nodeOfregion] # tries to get a line to the seeeee\n",
    "        #print(local_rivers)\n",
    "        # index of the point on the interpolated river line that is closest to the Tee point\n",
    "        rividx = [point.distance(x) for x in local_rivers].index(min([point.distance(x) for x in local_rivers]))\n",
    "        # gets the point along the river that is the distance along the river to the point nearest to the Tee\n",
    "        projected = local_rivers[rividx].interpolate(local_rivers[rividx].project(point))\n",
    "        distancefromN = point.distance(local_rivers[rividx]) # distance to that point\n",
    "    else:\n",
    "        projected = geom.Point(G.nodes[ridx]['pos'][0],G.nodes[ridx]['pos'][1],G.nodes[ridx]['elevation'])\n",
    "        distancefromN = point.distance(projected)\n",
    "    \n",
    "    if distancefromN==0 and distanceFromR==0:\n",
    "        distancefromN=1\n",
    "    # f2ik I think this is an interpolated elevation?\n",
    "    lerpedelevation = projected.z*(distanceFromR/(distanceFromR+distancefromN))+elevationAtClosestR*(distancefromN/(distanceFromR+distancefromN))\n",
    "    fixed = int(lerpedelevation)\n",
    "    #clear_output(wait=True)\n",
    "    #print(len(czs),\" out of \",len(allteepoints))  # use display(f) if you encounter performance issues\n",
    "\n",
    "    # find edges of node to which j,i are closest\n",
    "    #es = list(G.out_edges(n))+list(G.in_edges(n))\n",
    "    #closestEdge = [point_segment_distance_tuple((j,i),G.nodes[e[0]]['pos'], G.nodes[e[1]]['pos']) for e in es].index(min([point_segment_distance_tuple(j,i),G.nodes[e[0]]['pos'], G.nodes[e[1]]['pos']) for e in es]))\n",
    "    czs[t]=fixed\n",
    "\n",
    "# Add ridges as terrain primitives\n",
    "for q in ql:\n",
    "    #print(f'x:{ql[q][0]} y:{ql[q][1]}')\n",
    "    t = (int(ql[q][0]),int(ql[q][1]))\n",
    "    allteepoints.append(t)\n",
    "    czs[t] = qz[q]\n",
    "\n",
    "czsall = [czs[t] for t in allteepoints]\n",
    "allpoints_list = [[x[0],x[1]] for x in allteepoints]\n",
    "allpoints_nd = np.array(allteepoints)\n",
    "apkd = cKDTree(allpoints_nd)\n",
    "\n",
    "discard = imgray.copy()\n",
    "radius = 0\n",
    "while np.where(discard==255)[0].shape[0] >0:\n",
    "    radius+=1;\n",
    "    for tao in allteepoints:\n",
    "        cv.circle(discard,tao, radius, (0,0,0),-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TerrainFunction(point):\n",
    "    if imgray[point[1]][point[0]]==0:\n",
    "        return 0\n",
    "\n",
    "    # Gets and computes influence and elevation values for nearby terrain primitives\n",
    "    ts = apkd.query_ball_point(point,radius) # Gets all terrain primitives within a radius of the point\n",
    "    if len(ts) < 1: # if there just aren't any T points around, just put it in the ocean\n",
    "        return 0\n",
    "    wts = [w(distance(point,allteepoints[t])) for t in ts] # \"influence field\" radii of those primitives\n",
    "    hts = [ht(point,allteepoints[t]) for t in ts]          # elevations of those primitives\n",
    "\n",
    "    # Blends the terrain primitives\n",
    "    ht_ = height_b(hts,wts) # Blends those terrain primitives\n",
    "    wt_ = wts[0]            # I guess this is supposed to be the influence radius of the closest primitive?\n",
    "    \n",
    "    wi=wt_ # IDK why he converts these here\n",
    "    hi=ht_\n",
    "    \n",
    "    # Prepares to carve the terrain with the river\n",
    "    ridx = imgvoronoi[point[1]][point[0]]-1 # Region id of voronoi cell\n",
    "    if ridx==-1:\n",
    "        return hi\n",
    "    node = list(vor.point_region).index(ridx) # This just gets the number of the node\n",
    "    geomp = geom.Point(point[0],point[1])     # Creates a Shapely point out of the input point\n",
    "    rs = [ ]\n",
    "    hrs = [ ]\n",
    "    wrs = [ ]\n",
    "    if node in rivers: # Sometimes there isn't a river, just a drainage point along the seeeee\n",
    "        rs  = [e for e in rivers[node] if geomp.distance(e) < radius ]\n",
    "        hrs = [hr(geomp,e) for e in rs]\n",
    "        wrs = [w(geomp.distance(e)) for e in rs]\n",
    "    else:\n",
    "        riverPoint = geom.Point(G.nodes[ridx]['pos'][0],G.nodes[ridx]['pos'][1],G.nodes[ridx]['elevation'])\n",
    "        if geomp.distance(riverPoint) < radius:\n",
    "            rs = [ geomp.distance(riverPoint) ]\n",
    "            hrs = [ river.z ]\n",
    "            wrs = [ w(geomp.distance(riverPoint)) ]\n",
    "\n",
    "    # Height and \"influence field\" calculation per the last equation in Section 7\n",
    "    # This is the so-called \"replacement operator\"\n",
    "    for i in range(len(rs)): \n",
    "        hi=(1-wrs[i])*hi+wrs[i]*hrs[i] \n",
    "        wi = (1-wrs[i])*wi+wrs[i]**2\n",
    "\n",
    "    if hi<0:\n",
    "        #print(hrs,wrs)\n",
    "        pass\n",
    "    \n",
    "    return hi\n",
    "\n",
    "def height_b(h,w): # height function of a blend node (section 7)\n",
    "    try:\n",
    "        ret = np.sum(np.multiply(h,w))/(np.sum(w))\n",
    "        assert(ret>=0)\n",
    "        assert(not np.isnan(ret)) # make sure ret is a number\n",
    "        return ret\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "scale = 100.0 # I think adjusting these values could be useful\n",
    "octaves = 6\n",
    "persistence = 0.5\n",
    "lacunarity = 2.0\n",
    "def ht(p,t): # Height of a terrain primitive\n",
    "    return czs[t] +pnoise2(p[0]/scale,p[1]/scale,octaves=octaves,persistence=persistence,lacunarity=lacunarity,repeatx=imgray.shape[0],repeaty=imgray.shape[1],base=0)*10\n",
    "\n",
    "\n",
    "def hr(p,r): # Height of a river primitive?\n",
    "    d=p.distance(r)\n",
    "    # TODO profile based on Rosgen classification\n",
    "    segma = 0.1 * min(rwidth**2,d**2) # I think this is the river profile (evidently the author can't read Greek)\n",
    "    projected = r.interpolate(r.project(p))\n",
    "    #if projected.z<0:\n",
    "    #    print(\"0\")\n",
    "    return projected.z+segma\n",
    "\n",
    "\n",
    "def w(d): # This returns the \"influence field\" (section 7)\n",
    "    if d <1:\n",
    "        return 1;\n",
    "    return (max(0,(radius+1)-d)/((radius+1)*d))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "s= datetime.datetime.now()\n",
    "imgTest = np.zeros(imgray.shape,dtype='uint16')\n",
    "maxT=s-s;\n",
    "ijAtMaxT=None\n",
    "for i in trange(int(imgray.shape[0])): #, desc='1st loop'):\n",
    "    for j in range(imgray.shape[1]): #trange(imgray.shape[1], desc='2nd loop',leave=False):\n",
    "        ts =  datetime.datetime.now()\n",
    "        imgTest[i][j] = max(0,int(TerrainFunction((j,i))))\n",
    "        te =  datetime.datetime.now()\n",
    "        if (te-ts) > maxT:\n",
    "            maxT= te-ts\n",
    "            ijAtMaxT = (i,j)\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "plt.imshow(imgTest)\n",
    "e=datetime.datetime.now()\n",
    "print(\"End:\",e)\n",
    "print(\"render time: \", e -s )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work because\n",
    "immtt = np.array(imgTest)\n",
    "normalizedImg = immtt.copy()\n",
    "cv.normalize(immtt,  normalizedImg, 0, 255, cv.NORM_MINMAX)\n",
    "normalizedImg = normalizedImg.astype('uint8')\n",
    "cv.imwrite(\"taiwan-out.png\",normalizedImg)\n",
    "print(normalizedImg[800][800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = datetime.datetime.now()\n",
    "print(\"Total time: \", endTime -startTime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT.asdads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s= datetime.datetime.now()\n",
    "print(\"start:\",s)\n",
    "#imgTest = np.zeros(imgray.shape,dtype='uint8')\n",
    " \n",
    "print(TerrainFunction((326, 196)))\n",
    "print(TerrainFunction((196, 326)))\n",
    "\n",
    "e=datetime.datetime.now()\n",
    "print(\"End:\",e)\n",
    "print(\"render time: \", e -s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s= datetime.datetime.now()\n",
    "print(\"start:\",s)\n",
    "#imgTest = np.zeros(imgray.shape,dtype='uint8')\n",
    "\n",
    "imgTest = [[int(TerrainFunction((j,i))) for j in range(128,160)] for i in range(128,160)]\n",
    "\n",
    "plt.imshow(imgTest)\n",
    "e=datetime.datetime.now()\n",
    "print(\"End:\",e)\n",
    "print(\"render time: \", e -s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
